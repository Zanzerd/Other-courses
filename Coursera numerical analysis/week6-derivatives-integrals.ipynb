{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. One-sided finite differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a one-sided finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(f, x, h):\n",
    "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
    "    \n",
    "    Compute the derivative using the one-sided rule of the approximation order of $O(h^2)$.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        The function to differentiate\n",
    "    x : float\n",
    "        The point to compute the derivative at.\n",
    "    h : float\n",
    "        The step size for the finite different rule.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fder : derivative of f(x) at point x using the step size h.\n",
    "    \"\"\"\n",
    "    x1 = x + h #keeping them consistent \n",
    "    x2 = x+ 2*h\n",
    "    dx = x1 - x\n",
    "    fder = ((-3/2)*f(x) +  2*f(x1) - (1/2)*f(x2))/dx #This formula was written by Evgeny in \"Higher order schemes\" lesson\n",
    "    return fder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test I.1\n",
    "\n",
    "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Comment on whether your results are consistent with the expected value of $f'(x) = 0$ and on an expected scaling with $h\\to 0$.\n",
    "\n",
    " (10% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.0002\n",
      "0.001000 --  -2e-06\n",
      "0.000100 --  -2e-08\n",
      "0.000010 --  -2e-10\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(lambda x: x**3, x, h)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ... ENTER YOUR COMMENTS HERE ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My results are consistent with the scaling - with each new zero in step size we have 2 new zeroes in the derivative at $x = 0$. It is working as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.2\n",
    "\n",
    "Now use a slightly more complicated function, $f(x) = x^2 \\log{x}$, evaluate the derivative at $x=1$ using your one-sided rule and a two-point one-sided rule. Roughly estimate the value of $h$ where the error stops decreasing, for these two schemes. \n",
    "(15% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def f(x):\n",
    "    return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    return x * (2.*log(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twopoint_oneside(f, x, h): \n",
    "    x1 = x + h\n",
    "    dx = x1 - x\n",
    "    df = f(x1) - f(x)\n",
    "    return df/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ground truth' value: 1.0\n",
      "with approximation order O(h^2): 0.9999999999444366\n",
      "with approximation order O(h): 1.0000150000333332\n"
     ]
    }
   ],
   "source": [
    "h = 1e-5\n",
    "x0 = 1\n",
    "true_der = fder(x0)\n",
    "h2_der = deriv(f, x0, h)\n",
    "h1_der = twopoint_oneside(f, x0, h)\n",
    "print(\"'Ground truth' value: \" + str(true_der) + \"\\nwith approximation order O(h^2): \"+ str(h2_der) + \n",
    "      \"\\nwith approximation order O(h): \" + str(h1_der))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deriv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e5592e507d8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mh1_der_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh_arr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mh2_der_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mderiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrue_der\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mh1_der_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwopoint_oneside\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrue_der\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'deriv' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h_arr = np.logspace(-4, -15, num = 14)\n",
    "h2_der_arr = []\n",
    "h1_der_arr = []\n",
    "for h_i in h_arr:\n",
    "    h2_der_arr.append(abs(deriv(f, x0, h_i) - true_der))\n",
    "    h1_der_arr.append(abs(twopoint_oneside(f, x0, h_i) - true_der))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(h_arr, h1_der_arr , color = 'blue', marker = 'o')\n",
    "ax.plot(h_arr, h2_der_arr, color = 'red', marker = 'x')\n",
    "\n",
    "plt.ylim(1e-12, 1e-9)  \n",
    "plt.xlim(1e-15, 1e-7)\n",
    "\n",
    "_, ax2  = plt.subplots(figsize=(8,6))\n",
    "ax2.plot(h_arr, h1_der_arr , color = 'blue', marker = 'o')\n",
    "ax2.plot(h_arr, h2_der_arr, color = 'red', marker = 'x')\n",
    "\n",
    "plt.ylim(1e-9, 1e-6)  \n",
    "plt.xlim(1e-15, 1e-7)\n",
    "\n",
    "_, ax3  = plt.subplots(figsize=(8,6))\n",
    "ax3.plot(h_arr, h1_der_arr , color = 'blue', marker = 'o')\n",
    "ax3.plot(h_arr, h2_der_arr, color = 'red', marker = 'x')\n",
    "\n",
    "plt.ylim(1e-6, 1e-3)  \n",
    "plt.xlim(1e-15, 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the plots we can't estimate anything really, they are practically useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of step changes: [1.00000000e-04 1.42510267e-05 2.03091762e-06 2.89426612e-07\n",
      " 4.12462638e-08 5.87801607e-09 8.37677640e-10 1.19377664e-10\n",
      " 1.70125428e-11 2.42446202e-12 3.45510729e-13 4.92388263e-14\n",
      " 7.01703829e-15 1.00000000e-15]\n",
      "\n",
      "Array of errors for derivative with O(h): [0.00015000333324999282, 2.137660775147765e-05, 3.046377806237288e-06, 4.341399466589735e-07, 6.186939627284005e-08, 8.817023999796447e-09, 1.2565164464461986e-09, 1.7906631732955702e-10, 2.5518920310219073e-11, 3.6368685840670878e-12, 5.182521078950231e-13, 7.394085344003543e-14, 1.0658141036401503e-14, 1.5543122344752192e-15]\n",
      "\n",
      "Array of errors for derivative with O(h^2): [6.666166729729639e-09, 1.4318402019597443e-10, 5.191669316673142e-11, 5.573319583618286e-14, 2.6916955331302006e-09, 1.1102230246251565e-16, 1.3253582165084765e-07, 2.220446049250313e-16, 6.525881647290177e-06, 2.220446049250313e-16, 0.0, 1.1102230246251565e-16, 0.015625000000000666, 0.10000000000000053]\n"
     ]
    }
   ],
   "source": [
    "print(\"Array of step changes: \" +str(h_arr) +  \"\\n\\nArray of errors for derivative with O(h): \" + str(h1_der_arr) + \n",
    "      \"\\n\\nArray of errors for derivative with O(h^2): \" + str(h2_der_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, one sided two-point scheme's error decreases slower but does it without any difficulties. On the other hand, for our first scheme we see that error falls rapidly but rises again at some apparently random steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.3 \n",
    "\n",
    "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. \n",
    "(25% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.01386\n",
      "0.001000 -- -0.001386\n",
      "0.000100 -- -0.0001386\n",
      "0.000010 -- -1.386e-05\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x == 0:\n",
    "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x*(2*log(x) + 1)\n",
    "\n",
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(f, x, h) - fder(x)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the scaling is now $O(h)$, not $O(h^{2})$ as before. This happens probably due to roundoff errors which happen when we evaluate our function. Also, our choice of steps (h) is probably not optimal for this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Midpoint rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which computes a definite integral using the midpoint rule up to a given error, $\\epsilon$. Estimate the error by comparing the estimates of the integral at $N$ and $2N$ elementary intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint_rule(func, a, b, eps):\n",
    "    \"\"\" Calculate the integral of f from a to b using the midpoint rule.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        The function to integrate.\n",
    "    a : float\n",
    "        The lower limit of integration.\n",
    "    b : float\n",
    "        The upper limit of integration.\n",
    "    eps : float\n",
    "        The target accuracy of the estimate.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    integral : float\n",
    "        The estimate of $\\int_a^b f(x) dx$.\n",
    "    \"\"\"\n",
    "    Q = 0\n",
    "    Q_prev = np.inf\n",
    "    N = 50 #starting with 50 points mesh\n",
    "    i = 0\n",
    "    while(abs(Q - Q_prev) >= eps):\n",
    "        i+=1\n",
    "        Q_prev = Q\n",
    "        mesh = np.linspace(a, b, N)\n",
    "        h = (b-a)/N\n",
    "        Q = 0\n",
    "        for i in range(N-1):\n",
    "            xk_prev = mesh[i]\n",
    "            xk = mesh[i+1]\n",
    "            Qk = h*func((xk_prev + xk)/2)\n",
    "            Q += Qk\n",
    "            #print(abs(Q - Q_prev))\n",
    "        i+=1    \n",
    "        N = 2*N\n",
    "    return Q, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2576745200831851e-17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = lambda x: (x)/(16-(x**4))\n",
    "\n",
    "val, it = midpoint_rule(func, -1, 1, 1e-4)\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.1\n",
    "\n",
    "Test your midpoint rule on a simple integral, which you can calculate by paper and pencil.\n",
    "\n",
    "Compare the rate of convergence to the expected $O(N^{-2})$ scaling by studying the number of intervals required for a given accuracy $\\epsilon$.\n",
    "\n",
    "Compare the numerical results to the value you calculated by hand. Does the deviation agree with your estimate of the numerical error?\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9597979797979805\n",
      "99\n",
      "3.994996871088866\n",
      "799\n",
      "3.9993749511642496\n",
      "6399\n",
      "3.9999218742370464\n",
      "51199\n",
      "3.9999902343630147\n",
      "409599\n"
     ]
    }
   ],
   "source": [
    "func = lambda x: x**3\n",
    "for eps in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    val, it = midpoint_rule(func, 0, 2, eps) #the true value of this integral is 4\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations agree with my expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.2\n",
    "\n",
    "Now use your midpoint rule to compute the value of\n",
    "\n",
    "$$\n",
    "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx\n",
    "$$\n",
    "\n",
    "up to a predefined accuracy of $\\epsilon=10^{-4}$.\n",
    "\n",
    "Note that the integral contains an integrable singularity at the lower limit. Do calculations two ways: first, do a straightforward computation; next, subtract the singularity. Compare the number of iterations required to achieve the accuracy of $\\epsilon$.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "func2 = lambda x: np.sin(np.sqrt(x))/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer 1.8919295634977242 was given after 6553599 iterations.\n"
     ]
    }
   ],
   "source": [
    "val2, it = midpoint_rule(func2, 0, 1, 1e-4)\n",
    "print(\"The answer \" + str(val2) + \" was given after \" +str(it) + \" iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's subtract the singularity: \n",
    "\n",
    "$$\n",
    "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx = \\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x} - \\frac{1}{\\sqrt{x}}\\, dx + \\int_0^1\\! \\frac{1}{\\sqrt{x}}\\, dx\n",
    "$$\n",
    "\n",
    "And note that:\n",
    "$$\n",
    "\\int_0^1\\! \\frac{1}{\\sqrt{x}}\\, dx = 2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "func2_mod = lambda x: np.sin(np.sqrt(x))/x - 1/np.sqrt(x)\n",
    "func2_tail = lambda x: 1/np.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer -0.10776662055400743 was given after 1599 iterations.\n"
     ]
    }
   ],
   "source": [
    "val2_mod, it2 = midpoint_rule(func2_mod, 0, 1, 1e-4)\n",
    "print(\"The answer \" + str(val2_mod) + \" was given after \" +str(it2) + \" iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's add the singularity we had integrated by paper and pencil to get the answer: 1.8922333794459925\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's add the singularity we had integrated by paper and pencil to get the answer:\", val2_mod + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our first answer didn't even fit into 1e-4 bound (unlike this one)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
